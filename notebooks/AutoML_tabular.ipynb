{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SuperbTUM/ModelShare_Development/blob/master/notebooks/AutoML_tabular.ipynb)"
      ],
      "metadata": {
        "id": "aU0szSMsH0HZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QP_1B3Njmy4_",
        "outputId": "ec1b22a7-0b11-45cf-959a-1d8d23f945cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 951 kB 13.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 42.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 61.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 308 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 288 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 442 kB 74.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 83 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 55.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 66.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 146 kB 73.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 178 kB 78.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 82.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87 kB 7.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 46 kB 167 kB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 93.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.5 MB/s \n",
            "\u001b[?25h  Building wheel for Pympler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dabl\n",
            "  Downloading dabl-0.2.4-py3-none-any.whl (563 kB)\n",
            "\u001b[K     |████████████████████████████████| 563 kB 39.4 MB/s \n",
            "\u001b[?25hCollecting scikit-learn>=1.0\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from dabl) (1.21.6)\n",
            "Collecting matplotlib>=3.4\n",
            "  Downloading matplotlib-3.5.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 78.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from dabl) (1.7.3)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from dabl) (0.11.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from dabl) (1.3.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->dabl) (7.1.2)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 90.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->dabl) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->dabl) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->dabl) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->dabl) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.4->dabl) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.4->dabl) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib>=3.4->dabl) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->dabl) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->dabl) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->dabl) (2022.6)\n",
            "Installing collected packages: fonttools, matplotlib, scikit-learn, dabl\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.24.2\n",
            "    Uninstalling scikit-learn-0.24.2:\n",
            "      Successfully uninstalled scikit-learn-0.24.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "aimodelshare 0.0.142 requires scikit-learn==0.24.2, but you have scikit-learn 1.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed dabl-0.2.4 fonttools-4.38.0 matplotlib-3.5.3 scikit-learn-1.0.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mljar-supervised\n",
            "  Downloading mljar-supervised-0.11.3.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 32.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (1.3.5)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (1.0.2)\n",
            "Collecting xgboost>=1.3.3\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 255.9 MB 54 kB/s \n",
            "\u001b[?25hCollecting lightgbm>=3.0.0\n",
            "  Downloading lightgbm-3.3.3-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 56.6 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.24.4\n",
            "  Downloading catboost-1.1.1-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (1.2.0)\n",
            "Requirement already satisfied: tabulate>=0.8.7 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (0.8.10)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (3.5.3)\n",
            "Collecting dtreeviz>=1.3.3\n",
            "  Downloading dtreeviz-1.4.0-py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting shap>=0.36.0\n",
            "  Downloading shap-0.41.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (569 kB)\n",
            "\u001b[K     |████████████████████████████████| 569 kB 91.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (0.11.2)\n",
            "Requirement already satisfied: wordcloud>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (1.8.2.2)\n",
            "Collecting category_encoders>=2.2.2\n",
            "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 807 kB/s \n",
            "\u001b[?25hCollecting optuna>=2.7.0\n",
            "  Downloading optuna-3.0.3-py3-none-any.whl (348 kB)\n",
            "\u001b[K     |████████████████████████████████| 348 kB 60.1 MB/s \n",
            "\u001b[?25hCollecting scikit-plot==0.3.7\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from mljar-supervised) (4.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->mljar-supervised) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->mljar-supervised) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->mljar-supervised) (5.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders>=2.2.2->mljar-supervised) (0.12.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders>=2.2.2->mljar-supervised) (0.5.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from dtreeviz>=1.3.3->mljar-supervised) (3.6.4)\n",
            "Collecting colour\n",
            "  Downloading colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=3.0.0->mljar-supervised) (0.38.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (0.11.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->mljar-supervised) (2.8.2)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=2.7.0->mljar-supervised) (1.4.43)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.9.0-py3-none-any.whl (23 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 60.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna>=2.7.0->mljar-supervised) (6.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna>=2.7.0->mljar-supervised) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata<5.0.0 in /usr/local/lib/python3.7/dist-packages (from optuna>=2.7.0->mljar-supervised) (4.13.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic>=1.5.0->optuna>=2.7.0->mljar-supervised) (5.10.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<5.0.0->optuna>=2.7.0->mljar-supervised) (3.10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->mljar-supervised) (2022.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0->mljar-supervised) (3.1.0)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap>=0.36.0->mljar-supervised) (1.5.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap>=0.36.0->mljar-supervised) (0.56.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.3.0->optuna>=2.7.0->mljar-supervised) (2.0.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.2-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.9 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 71.5 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.11.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna>=2.7.0->mljar-supervised) (3.5.0)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=2.7.0->mljar-supervised) (22.1.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna>=2.7.0->mljar-supervised) (0.2.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic>=1.5.0->optuna>=2.7.0->mljar-supervised) (2.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap>=0.36.0->mljar-supervised) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap>=0.36.0->mljar-supervised) (0.39.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.24.4->mljar-supervised) (8.1.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3.3->mljar-supervised) (9.0.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3.3->mljar-supervised) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3.3->mljar-supervised) (1.4.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->dtreeviz>=1.3.3->mljar-supervised) (1.11.0)\n",
            "Building wheels for collected packages: mljar-supervised, pyperclip\n",
            "  Building wheel for mljar-supervised (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mljar-supervised: filename=mljar_supervised-0.11.3-py3-none-any.whl size=146653 sha256=85db329157bdd61d7a544a0ff4b3b23798afd458a7e6a20e71611c38f73c83d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/d4/2a/d68abf3e680da91bf037f521faa319a58b711a22a334c62bfd\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=89d1fa28e2da262385d6fdc02ef833d6b47098c2be2da9385885e18af492f405\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built mljar-supervised pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, slicer, colour, colorlog, cmaes, cliff, alembic, xgboost, shap, scikit-plot, optuna, lightgbm, dtreeviz, category-encoders, catboost, mljar-supervised\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "Successfully installed Mako-1.2.4 alembic-1.8.1 autopage-0.5.1 catboost-1.1.1 category-encoders-2.5.1.post0 cliff-3.10.1 cmaes-0.9.0 cmd2-2.4.2 colorlog-6.7.0 colour-0.1.5 dtreeviz-1.4.0 lightgbm-3.3.3 mljar-supervised-0.11.3 optuna-3.0.3 pbr-5.11.0 pyperclip-1.8.2 scikit-plot-0.3.7 shap-0.41.0 slicer-0.0.7 stevedore-3.5.2 xgboost-1.6.2\n"
          ]
        }
      ],
      "source": [
        "!pip install aimodelshare --upgrade -q\n",
        "!pip install dabl\n",
        "!pip install mljar-supervised"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "import dabl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "X_train, X_test, y_train, y_test, example_data, y_test_labels = ai.import_quickstart_data(\"titanic\")\n",
        "\n",
        "types = dabl.detect_types(X_train)\n",
        "indices = list(types.index)\n",
        "names = types.columns.to_numpy()\n",
        "types = types.to_numpy()\n",
        "\n",
        "d = dict()\n",
        "for index, tpes in zip(indices, types):\n",
        "  for name, tpe in zip(names, tpes):\n",
        "    if tpe:\n",
        "      d[index] = name\n",
        "  \n",
        "X_train_processed = dabl.clean(X_train, type_hints=d)\n",
        "X_test_processed = dabl.clean(X_test, type_hints=d)\n",
        "\n",
        "preprocessor = dabl.EasyPreprocessor()\n",
        "preprocessor.fit(X_train_processed)\n",
        "X_train_processed = preprocessor.transform(X_train_processed)\n",
        "preprocessor.fit(X_test_processed)\n",
        "X_test_processed = preprocessor.transform(X_test_processed)\n",
        "\n",
        "y_train_labels_processed = np.asarray(list(map(lambda x: 0 if x == y_test_labels[0] else 1, y_train))).reshape(len(X_train), 1)\n",
        "y_test_labels_processed = np.asarray(list(map(lambda x: 0 if x == y_test_labels[0] else 1, y_test)))\n",
        "\n",
        "titanic = pd.DataFrame(np.concatenate((X_train_processed, y_train_labels_processed), axis=1), columns=[\"feature_\" + str(i) for i in range(X_train_processed.shape[1])] + [\"classification\"])\n",
        "ec = dabl.SimpleClassifier(random_state=0).fit(titanic, target_col=\"classification\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYxRlOCSr_Ad",
        "outputId": "c0ebc518-60e5-4a58-dd53-4674a3617abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [===>                                             ]\n",
            "\n",
            "Data downloaded successfully.\n",
            "\n",
            "Preparing downloaded files for use...\n",
            "\n",
            "Success! Your Quick Start materials have been downloaded. \n",
            "You are now ready to run the tutorial.\n",
            "Running DummyClassifier(random_state=0)\n",
            "accuracy: 0.625 average_precision: 0.375 roc_auc: 0.500 recall_macro: 0.500 f1_macro: 0.384\n",
            "=== new best DummyClassifier(random_state=0) (using recall_macro):\n",
            "accuracy: 0.625 average_precision: 0.375 roc_auc: 0.500 recall_macro: 0.500 f1_macro: 0.384\n",
            "\n",
            "Running GaussianNB()\n",
            "accuracy: 0.765 average_precision: 0.764 roc_auc: 0.820 recall_macro: 0.764 f1_macro: 0.755\n",
            "=== new best GaussianNB() (using recall_macro):\n",
            "accuracy: 0.765 average_precision: 0.764 roc_auc: 0.820 recall_macro: 0.764 f1_macro: 0.755\n",
            "\n",
            "Running MultinomialNB()\n",
            "accuracy: 0.770 average_precision: 0.810 roc_auc: 0.834 recall_macro: 0.763 f1_macro: 0.758\n",
            "Running DecisionTreeClassifier(class_weight='balanced', max_depth=1, random_state=0)\n",
            "accuracy: 0.781 average_precision: 0.613 roc_auc: 0.763 recall_macro: 0.763 f1_macro: 0.765\n",
            "Running DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=0)\n",
            "accuracy: 0.788 average_precision: 0.760 roc_auc: 0.828 recall_macro: 0.779 f1_macro: 0.775\n",
            "=== new best DecisionTreeClassifier(class_weight='balanced', max_depth=5, random_state=0) (using recall_macro):\n",
            "accuracy: 0.788 average_precision: 0.760 roc_auc: 0.828 recall_macro: 0.779 f1_macro: 0.775\n",
            "\n",
            "Running DecisionTreeClassifier(class_weight='balanced', min_impurity_decrease=0.01,\n",
            "                       random_state=0)\n",
            "accuracy: 0.796 average_precision: 0.747 roc_auc: 0.825 recall_macro: 0.781 f1_macro: 0.781\n",
            "=== new best DecisionTreeClassifier(class_weight='balanced', min_impurity_decrease=0.01,\n",
            "                       random_state=0) (using recall_macro):\n",
            "accuracy: 0.796 average_precision: 0.747 roc_auc: 0.825 recall_macro: 0.781 f1_macro: 0.781\n",
            "\n",
            "Running LogisticRegression(C=0.1, class_weight='balanced', max_iter=1000,\n",
            "                   random_state=0)\n",
            "accuracy: 0.775 average_precision: 0.804 roc_auc: 0.839 recall_macro: 0.772 f1_macro: 0.765\n",
            "Running LogisticRegression(C=1, class_weight='balanced', max_iter=1000, random_state=0)\n",
            "accuracy: 0.776 average_precision: 0.804 roc_auc: 0.840 recall_macro: 0.777 f1_macro: 0.768\n",
            "\n",
            "Best model:\n",
            "DecisionTreeClassifier(class_weight='balanced', min_impurity_decrease=0.01,\n",
            "                       random_state=0)\n",
            "Best Scores:\n",
            "accuracy: 0.796 average_precision: 0.747 roc_auc: 0.825 recall_macro: 0.781 f1_macro: 0.781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seems that dabl does not include xgboost, lightgbm...try another automl lib instead\n",
        "\n",
        "Default algos: catboost, xgboost, random forest, lightgbm...\n",
        "\n",
        "Automatically test all possible models by setting mode to 'Compete'"
      ],
      "metadata": {
        "id": "IoCgoPNvnXcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "automl_dir = \"AutoML_classifier\"\n",
        "if os.path.exists(automl_dir):\n",
        "    shutil.rmtree(automl_dir)"
      ],
      "metadata": {
        "id": "e1HvsG2lqc-9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI5lWfqEiM38",
        "outputId": "a3ef4574-d876-431b-8ef4-327e9f4cbc7d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.5.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import aimodelshare as ai\n",
        "from supervised.automl import AutoML\n",
        "\n",
        "X_train, X_test, y_train, y_test, example_data, y_test_labels = ai.import_quickstart_data(\"titanic\")\n",
        "\n",
        "# automl = AutoML(results_path=automl_dir, mode=\"Compete\")\n",
        "automl = AutoML(results_path=automl_dir, mode=\"Perform\")\n",
        "automl.fit(X_train, y_train)\n",
        "\n",
        "predictions = automl.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbrt5IB6m1w3",
        "outputId": "2cd205ae-4ad4-449c-8b40-bf218c53cb8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading [===>                                             ]\n",
            "\n",
            "Data downloaded successfully.\n",
            "\n",
            "Preparing downloaded files for use...\n",
            "\n",
            "Success! Your Quick Start materials have been downloaded. \n",
            "You are now ready to run the tutorial.\n",
            "AutoML directory: AutoML_classifier\n",
            "The task is binary_classification with evaluation metric logloss\n",
            "AutoML will use algorithms: ['Linear', 'Random Forest', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network']\n",
            "AutoML will ensemble available models\n",
            "AutoML steps: ['simple_algorithms', 'default_algorithms', 'not_so_random', 'golden_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'ensemble']\n",
            "* Step simple_algorithms will try to check up to 1 model\n",
            "1_Linear logloss 0.4593 trained in 2.99 seconds (1-sample predict time 0.0649 seconds)\n",
            "* Step default_algorithms will try to check up to 5 models\n",
            "2_Default_LightGBM logloss 0.451374 trained in 2.57 seconds (1-sample predict time 0.0296 seconds)\n",
            "3_Default_Xgboost logloss 0.43645 trained in 8.95 seconds (1-sample predict time 0.0659 seconds)\n",
            "4_Default_CatBoost logloss 0.426321 trained in 3.49 seconds (1-sample predict time 0.027 seconds)\n",
            "5_Default_NeuralNetwork logloss 0.458215 trained in 3.59 seconds (1-sample predict time 0.0483 seconds)\n",
            "6_Default_RandomForest logloss 0.431745 trained in 14.95 seconds (1-sample predict time 0.5487 seconds)\n",
            "* Step not_so_random will try to check up to 20 models\n",
            "11_LightGBM logloss 0.436835 trained in 3.55 seconds (1-sample predict time 0.0309 seconds)\n",
            "7_Xgboost logloss 0.435824 trained in 10.06 seconds (1-sample predict time 0.0645 seconds)\n",
            "15_CatBoost logloss 0.43213 trained in 4.45 seconds (1-sample predict time 0.0317 seconds)\n",
            "19_RandomForest logloss 0.442529 trained in 15.41 seconds (1-sample predict time 0.5505 seconds)\n",
            "23_NeuralNetwork logloss 0.483916 trained in 4.14 seconds (1-sample predict time 0.0527 seconds)\n",
            "12_LightGBM logloss 0.451377 trained in 3.31 seconds (1-sample predict time 0.0466 seconds)\n",
            "8_Xgboost logloss 0.449364 trained in 8.53 seconds (1-sample predict time 0.0557 seconds)\n",
            "16_CatBoost logloss 0.427597 trained in 4.72 seconds (1-sample predict time 0.0258 seconds)\n",
            "20_RandomForest logloss 0.435957 trained in 17.52 seconds (1-sample predict time 0.5498 seconds)\n",
            "24_NeuralNetwork logloss 0.45503 trained in 4.65 seconds (1-sample predict time 0.0514 seconds)\n",
            "13_LightGBM logloss 0.443994 trained in 4.11 seconds (1-sample predict time 0.0338 seconds)\n",
            "9_Xgboost logloss 0.446169 trained in 22.73 seconds (1-sample predict time 0.0563 seconds)\n",
            "17_CatBoost logloss 0.43198 trained in 5.37 seconds (1-sample predict time 0.0311 seconds)\n",
            "21_RandomForest logloss 0.439431 trained in 15.84 seconds (1-sample predict time 0.551 seconds)\n",
            "25_NeuralNetwork logloss 0.491455 trained in 7.63 seconds (1-sample predict time 0.0523 seconds)\n",
            "14_LightGBM logloss 0.451559 trained in 4.8 seconds (1-sample predict time 0.0348 seconds)\n",
            "10_Xgboost logloss 0.604882 trained in 18.06 seconds (1-sample predict time 0.0643 seconds)\n",
            "18_CatBoost logloss 0.432409 trained in 5.47 seconds (1-sample predict time 0.036 seconds)\n",
            "22_RandomForest logloss 0.436207 trained in 17.63 seconds (1-sample predict time 0.552 seconds)\n",
            "26_NeuralNetwork logloss 0.476851 trained in 5.75 seconds (1-sample predict time 0.0603 seconds)\n",
            "* Step golden_features will try to check up to 3 models\n",
            "None 10\n",
            "Add Golden Feature: age_ratio_fare\n",
            "Add Golden Feature: fare_sum_age\n",
            "Add Golden Feature: fare_multiply_age\n",
            "Add Golden Feature: fare_ratio_age\n",
            "Add Golden Feature: age_sum_pclass\n",
            "Add Golden Feature: pclass_diff_age\n",
            "Add Golden Feature: age_multiply_pclass\n",
            "Add Golden Feature: pclass_ratio_fare\n",
            "Add Golden Feature: pclass_ratio_age\n",
            "Add Golden Feature: age_ratio_pclass\n",
            "Created 10 Golden Features in 0.05 seconds.\n",
            "4_Default_CatBoost_GoldenFeatures logloss 0.436604 trained in 7.16 seconds (1-sample predict time 0.0554 seconds)\n",
            "16_CatBoost_GoldenFeatures logloss 0.439418 trained in 10.44 seconds (1-sample predict time 0.0564 seconds)\n",
            "6_Default_RandomForest_GoldenFeatures logloss 0.437758 trained in 31.62 seconds (1-sample predict time 0.5794 seconds)\n",
            "* Step insert_random_feature will try to check up to 1 model\n",
            "4_Default_CatBoost_RandomFeature logloss 0.433089 trained in 6.49 seconds (1-sample predict time 0.0361 seconds)\n",
            "Drop features ['random_feature']\n",
            "Skip features_selection because no parameters were generated.\n",
            "* Step hill_climbing_1 will try to check up to 16 models\n",
            "27_CatBoost logloss 0.422919 trained in 6.45 seconds (1-sample predict time 0.0326 seconds)\n",
            "28_CatBoost logloss 0.42422 trained in 6.68 seconds (1-sample predict time 0.0394 seconds)\n",
            "29_RandomForest logloss 0.427125 trained in 17.48 seconds (1-sample predict time 0.5685 seconds)\n",
            "30_RandomForest logloss 0.428814 trained in 18.01 seconds (1-sample predict time 0.5533 seconds)\n",
            "31_Xgboost logloss 0.451481 trained in 12.05 seconds (1-sample predict time 0.0729 seconds)\n",
            "32_Xgboost logloss 0.434224 trained in 20.36 seconds (1-sample predict time 0.0638 seconds)\n",
            "33_RandomForest logloss 0.434545 trained in 22.06 seconds (1-sample predict time 0.5706 seconds)\n",
            "34_RandomForest logloss 0.437521 trained in 19.4 seconds (1-sample predict time 0.5528 seconds)\n",
            "35_Xgboost logloss 0.433213 trained in 15.26 seconds (1-sample predict time 0.0648 seconds)\n",
            "36_LightGBM logloss 0.43683 trained in 6.89 seconds (1-sample predict time 0.0368 seconds)\n",
            "37_LightGBM logloss 0.436787 trained in 6.96 seconds (1-sample predict time 0.0309 seconds)\n",
            "38_LightGBM logloss 0.442592 trained in 7.11 seconds (1-sample predict time 0.0336 seconds)\n",
            "39_LightGBM logloss 0.443994 trained in 7.12 seconds (1-sample predict time 0.0301 seconds)\n",
            "40_NeuralNetwork logloss 0.452588 trained in 8.85 seconds (1-sample predict time 0.053 seconds)\n",
            "41_NeuralNetwork logloss 0.467996 trained in 8.1 seconds (1-sample predict time 0.0503 seconds)\n",
            "42_NeuralNetwork logloss 0.452597 trained in 8.15 seconds (1-sample predict time 0.0549 seconds)\n",
            "* Step hill_climbing_2 will try to check up to 18 models\n",
            "43_CatBoost logloss 0.425693 trained in 8.43 seconds (1-sample predict time 0.0286 seconds)\n",
            "44_CatBoost logloss 0.42578 trained in 8.37 seconds (1-sample predict time 0.0326 seconds)\n",
            "45_CatBoost logloss 0.429405 trained in 8.62 seconds (1-sample predict time 0.0288 seconds)\n",
            "46_CatBoost logloss 0.429657 trained in 9.13 seconds (1-sample predict time 0.0266 seconds)\n",
            "47_RandomForest logloss 0.427125 trained in 19.92 seconds (1-sample predict time 0.5532 seconds)\n",
            "48_RandomForest logloss 0.433362 trained in 19.97 seconds (1-sample predict time 0.5527 seconds)\n",
            "49_RandomForest logloss 0.428814 trained in 19.75 seconds (1-sample predict time 0.5597 seconds)\n",
            "50_RandomForest logloss 0.436284 trained in 19.89 seconds (1-sample predict time 0.5556 seconds)\n",
            "51_Xgboost logloss 0.43316 trained in 21.61 seconds (1-sample predict time 0.0589 seconds)\n",
            "52_Xgboost logloss 0.432418 trained in 16.84 seconds (1-sample predict time 0.0648 seconds)\n",
            "53_Xgboost logloss 0.433071 trained in 29.08 seconds (1-sample predict time 0.0667 seconds)\n",
            "54_Xgboost logloss 0.432842 trained in 22.08 seconds (1-sample predict time 0.0655 seconds)\n",
            "55_LightGBM logloss 0.436528 trained in 8.98 seconds (1-sample predict time 0.0307 seconds)\n",
            "56_LightGBM logloss 0.43683 trained in 9.04 seconds (1-sample predict time 0.0346 seconds)\n",
            "57_NeuralNetwork logloss 0.487567 trained in 10.08 seconds (1-sample predict time 0.0599 seconds)\n",
            "58_NeuralNetwork logloss 0.472891 trained in 10.69 seconds (1-sample predict time 0.0516 seconds)\n",
            "59_NeuralNetwork logloss 0.457768 trained in 9.92 seconds (1-sample predict time 0.0563 seconds)\n",
            "60_NeuralNetwork logloss 0.500989 trained in 10.39 seconds (1-sample predict time 0.0511 seconds)\n",
            "* Step ensemble will try to check up to 1 model\n",
            "Ensemble logloss 0.419197 trained in 11.1 seconds (1-sample predict time 0.2121 seconds)\n",
            "AutoML fit time: 853.77 seconds\n",
            "AutoML best model: Ensemble\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predictions)*100.0:.2f}%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nqD0pl1pnMJ",
        "outputId": "310958be-ad41-4c53-dbed-aa72ec7b2e51"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 78.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save automl model into onnx model is not supported yet"
      ],
      "metadata": {
        "id": "6UYPM8RZrw8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl.get_leaderboard()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "q95cRM2F7Jbz",
        "outputId": "e695528b-d95f-45bb-af67-61385143486e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       name      model_type metric_type  metric_value  \\\n",
              "0                  1_Linear          Linear     logloss      0.459300   \n",
              "1        2_Default_LightGBM        LightGBM     logloss      0.451374   \n",
              "2         3_Default_Xgboost         Xgboost     logloss      0.436450   \n",
              "3        4_Default_CatBoost        CatBoost     logloss      0.426321   \n",
              "4   5_Default_NeuralNetwork  Neural Network     logloss      0.458215   \n",
              "..                      ...             ...         ...           ...   \n",
              "60         57_NeuralNetwork  Neural Network     logloss      0.487567   \n",
              "61         58_NeuralNetwork  Neural Network     logloss      0.472891   \n",
              "62         59_NeuralNetwork  Neural Network     logloss      0.457768   \n",
              "63         60_NeuralNetwork  Neural Network     logloss      0.500989   \n",
              "64                 Ensemble        Ensemble     logloss      0.419197   \n",
              "\n",
              "    train_time  single_prediction_time  \n",
              "0         3.92                  0.0649  \n",
              "1         3.52                  0.0296  \n",
              "2         9.90                  0.0659  \n",
              "3         4.45                  0.0270  \n",
              "4         4.52                  0.0483  \n",
              "..         ...                     ...  \n",
              "60       11.10                  0.0599  \n",
              "61       11.68                  0.0516  \n",
              "62       10.87                  0.0563  \n",
              "63       11.56                  0.0511  \n",
              "64       11.10                  0.2121  \n",
              "\n",
              "[65 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c101c6b0-6263-4bc2-81d5-21d464214a91\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>model_type</th>\n",
              "      <th>metric_type</th>\n",
              "      <th>metric_value</th>\n",
              "      <th>train_time</th>\n",
              "      <th>single_prediction_time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_Linear</td>\n",
              "      <td>Linear</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.459300</td>\n",
              "      <td>3.92</td>\n",
              "      <td>0.0649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2_Default_LightGBM</td>\n",
              "      <td>LightGBM</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.451374</td>\n",
              "      <td>3.52</td>\n",
              "      <td>0.0296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3_Default_Xgboost</td>\n",
              "      <td>Xgboost</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.436450</td>\n",
              "      <td>9.90</td>\n",
              "      <td>0.0659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4_Default_CatBoost</td>\n",
              "      <td>CatBoost</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.426321</td>\n",
              "      <td>4.45</td>\n",
              "      <td>0.0270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5_Default_NeuralNetwork</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.458215</td>\n",
              "      <td>4.52</td>\n",
              "      <td>0.0483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>57_NeuralNetwork</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.487567</td>\n",
              "      <td>11.10</td>\n",
              "      <td>0.0599</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>58_NeuralNetwork</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.472891</td>\n",
              "      <td>11.68</td>\n",
              "      <td>0.0516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>59_NeuralNetwork</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.457768</td>\n",
              "      <td>10.87</td>\n",
              "      <td>0.0563</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>60_NeuralNetwork</td>\n",
              "      <td>Neural Network</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.500989</td>\n",
              "      <td>11.56</td>\n",
              "      <td>0.0511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Ensemble</td>\n",
              "      <td>Ensemble</td>\n",
              "      <td>logloss</td>\n",
              "      <td>0.419197</td>\n",
              "      <td>11.10</td>\n",
              "      <td>0.2121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c101c6b0-6263-4bc2-81d5-21d464214a91')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c101c6b0-6263-4bc2-81d5-21d464214a91 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c101c6b0-6263-4bc2-81d5-21d464214a91');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selected_models = automl.ensemble.selected_models\n",
        "models = []\n",
        "for model_ in selected_models:\n",
        "  model = model_[\"model\"]\n",
        "  models.append([model.get_name(), model])\n",
        "models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyT4BMlbUyuX",
        "outputId": "3235385e-5a45-4f69-bfe1-e2f0c446c336"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['27_CatBoost',\n",
              "  <supervised.model_framework.ModelFramework at 0x7f18e518f8d0>],\n",
              " ['28_CatBoost',\n",
              "  <supervised.model_framework.ModelFramework at 0x7f18e3072750>],\n",
              " ['3_Default_Xgboost',\n",
              "  <supervised.model_framework.ModelFramework at 0x7f18ede34650>],\n",
              " ['43_CatBoost',\n",
              "  <supervised.model_framework.ModelFramework at 0x7f18d81e40d0>],\n",
              " ['54_Xgboost', <supervised.model_framework.ModelFramework at 0x7f18d27ee410>]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get weights"
      ],
      "metadata": {
        "id": "WjNAUg76SiZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(automl_dir)"
      ],
      "metadata": {
        "id": "puh-A5SUNhPz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "loaded_model = []\n",
        "for model_name, model in models:\n",
        "  os.chdir(model_name)\n",
        "  \n",
        "  model.load(\"./\", \"\")\n",
        "  os.chdir(\"..\") \n",
        "\n",
        "  loaded_model.append(model)"
      ],
      "metadata": {
        "id": "UnGbjPoVNR4R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for model in loaded_model:\n",
        "  predictions = model.predict(X_test)\n",
        "  predict_cols = predictions.columns\n",
        "  predict_cols = np.asarray([name.split(\"_\")[-1] for name in predict_cols])\n",
        "  predictions = predict_cols[predictions.to_numpy().argmax(axis=-1)]\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, predictions)*100.0:.2f}%\" )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9-AgVrJZbgf",
        "outputId": "0c1eac13-3e34-4e2b-873f-70d14336080b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.01%\n",
            "Accuracy: 78.63%\n",
            "Accuracy: 78.24%\n",
            "Accuracy: 79.01%\n",
            "Accuracy: 80.53%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transform to onnx with ensemble model"
      ],
      "metadata": {
        "id": "GNMK1J7UTiem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_models = []\n",
        "\n",
        "for model_detail in models:\n",
        "  name, model = model_detail\n",
        "  preprocessor = model.preprocessings[0]\n",
        "  learner = model.learners[0].model\n",
        "  parsed_models.append((preprocessor, learner))"
      ],
      "metadata": {
        "id": "jGQ-Z1XgpB5d"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from skl2onnx import update_registered_converter\n",
        "from skl2onnx.common.shape_calculator import (\n",
        "    calculate_linear_classifier_output_shapes,\n",
        "    calculate_linear_regressor_output_shapes)\n",
        "import xgboost\n",
        "import lightgbm\n",
        "import catboost\n",
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from onnxmltools.convert.xgboost.operator_converters.XGBoost import (\n",
        "    convert_xgboost)\n",
        "from onnxmltools.convert import convert_xgboost as convert_xgboost_booster\n",
        "from onnxmltools.convert.lightgbm.operator_converters.LightGbm import convert_lightgbm\n",
        "\n",
        "import dabl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "preprocessor = parsed_models[0][0]\n",
        "X_train_transformed, y_train_transformed, _ = preprocessor.fit_and_transform(X_train, y_train)\n",
        "X_test_transformed, y_test_transformed, _ = preprocessor.fit_and_transform(X_test, y_test)\n",
        "\n",
        "model_pipelines = []\n",
        "\n",
        "\n",
        "for preprocessor, model in parsed_models:\n",
        "  # preprocessor.fit = preprocessor.fit_and_transform\n",
        "\n",
        "  # # Not a good idea\n",
        "  # def transforms(X_validation):\n",
        "  #   try:\n",
        "  #     return preprocessor.transform(X_validation, y_validation=None)[0]\n",
        "  #   except:\n",
        "  #     return preprocessor.transform(X_validation)\n",
        "  # preprocessor.transform = transforms\n",
        "  if not hasattr(model, \"fit\"):\n",
        "    \n",
        "    if isinstance(model, xgboost.core.Booster):\n",
        "      new_model = xgboost.XGBClassifier()\n",
        "      new_model._Booster = model\n",
        "\n",
        "      update_registered_converter(\n",
        "                      XGBClassifier, 'XGBoostXGBClassifier',\n",
        "                      calculate_linear_classifier_output_shapes, convert_xgboost,\n",
        "                      options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})\n",
        "    elif isinstance(model, lightgbm.Booster):\n",
        "      new_model = model\n",
        "      update_registered_converter(\n",
        "                     LGBMClassifier, 'LightGbmLGBMClassifier',\n",
        "                     calculate_linear_classifier_output_shapes, convert_lightgbm,\n",
        "                     options={'nocl': [True, False], 'zipmap': [True, False, 'columns']})\n",
        "\n",
        "    else:\n",
        "      raise NotImplementedError\n",
        "    assert hasattr(model, \"predict\")# and hasattr(preprocessor, \"fit\") and hasattr(preprocessor, \"transform\")\n",
        "    pipeline = new_model\n",
        "  else:\n",
        "    pipeline = model\n",
        "  model_pipelines.append(pipeline)\n",
        "\n",
        "\n",
        "estimators = [(\"model_\"+str(i), pipeline) for i, pipeline in enumerate(model_pipelines)]\n",
        "\n",
        "stacked_classifier = StackingClassifier(estimators=estimators, \n",
        "            final_estimator=LogisticRegression())\n",
        "\n",
        "pipeline = make_pipeline(stacked_classifier)\n",
        "\n",
        "print(pipeline)\n",
        "print(\"success\")\n",
        "\n",
        "pipeline.fit(X_train_transformed.to_numpy(), y_train_transformed)\n",
        "pipeline.score(X_test_transformed.to_numpy(), y_test_transformed)"
      ],
      "metadata": {
        "id": "uHcxqYFVa78d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178f7af0-4566-4790-eeae-e1bb99748fcc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline(steps=[('stackingclassifier',\n",
            "                 StackingClassifier(estimators=[('model_0',\n",
            "                                                 <catboost.core.CatBoostClassifier object at 0x7f18cec688d0>),\n",
            "                                                ('model_1',\n",
            "                                                 <catboost.core.CatBoostClassifier object at 0x7f18ce9f1950>),\n",
            "                                                ('model_2',\n",
            "                                                 XGBClassifier(base_score=0.5,\n",
            "                                                               booster='gbtree',\n",
            "                                                               callbacks=None,\n",
            "                                                               colsample_bylevel=1,\n",
            "                                                               colsample_bynode=1,\n",
            "                                                               colsample_bytree=1,\n",
            "                                                               early_stoppin...\n",
            "                                                               importance_type=None,\n",
            "                                                               interaction_constraints='',\n",
            "                                                               learning_rate=0.300000012,\n",
            "                                                               max_bin=256,\n",
            "                                                               max_cat_to_onehot=4,\n",
            "                                                               max_delta_step=0,\n",
            "                                                               max_depth=6,\n",
            "                                                               max_leaves=0,\n",
            "                                                               min_child_weight=1,\n",
            "                                                               missing=nan,\n",
            "                                                               monotone_constraints='()',\n",
            "                                                               n_estimators=100,\n",
            "                                                               n_jobs=0,\n",
            "                                                               num_parallel_tree=1,\n",
            "                                                               predictor='auto',\n",
            "                                                               random_state=0,\n",
            "                                                               reg_alpha=0,\n",
            "                                                               reg_lambda=1, ...))],\n",
            "                                    final_estimator=LogisticRegression()))])\n",
            "success\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7977099236641222"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Catboost is not that easy\n",
        "```\n",
        "model.save_model(\n",
        "    \"model.onnx\",\n",
        "    format=\"onnx\",\n",
        "    export_parameters={\n",
        "        'onnx_domain': 'ai.catboost',\n",
        "        'onnx_model_version': 1,\n",
        "        'onnx_doc_string': 'test model for MultiClassification',\n",
        "        'onnx_graph_name': 'CatBoostModel_for_MultiClassification'\n",
        "    }\n",
        ")\n",
        "```"
      ],
      "metadata": {
        "id": "lcVyf3ykVtg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from aimodelshare.aimsonnx import model_to_onnx # Not working with Catboost\n",
        "#from skl2onnx import convert_sklearn\n",
        "from onnxmltools import convert_sklearn\n",
        "from onnxmltools.utils import save_model\n",
        "\n",
        "# Check how many preprocessed input features there are\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "initial_types = [('float_input', FloatTensorType([None, X_train.shape[1]]))]  # Insert correct number of features in preprocessed data\n",
        "\n",
        "# onnx_model = convert_sklearn(\n",
        "#     pipeline, 'pipeline_ensemble',\n",
        "#     initial_types,\n",
        "#     target_opset={'': 12, 'ai.onnx.ml': 2})\n",
        "# onnx_model = model_to_onnx(pipeline, framework='sklearn',\n",
        "#               initial_types=initial_types,\n",
        "#               transfer_learning=False, deep_learning=False)\n",
        "\n",
        "# with open(\"model.onnx\", \"wb\") as f:\n",
        "#     f.write(onnx_model.SerializeToString())\n",
        "\n",
        "onnx_model = convert_sklearn(pipeline, initial_types=initial_types, target_opset={'': 12, 'ai.onnx.ml': 2})\n",
        "save_model(onnx_model, \"model.onnx\")\n"
      ],
      "metadata": {
        "id": "mShSQZggrwVk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40f35449-91a8-4e61-ccfc-8f6013403966"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-16b9e25d21a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     f.write(onnx_model.SerializeToString())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_sklearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ai.onnx.ml'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/onnxmltools/convert/main.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, targeted_onnx, custom_conversion_functions, custom_shape_calculators)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mskl2onnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconvert_sklearn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconvert_skl2onnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     return convert_skl2onnx(model, name, initial_types, doc_string, target_opset,\n\u001b[0;32m--> 154\u001b[0;31m                             custom_conversion_functions, custom_shape_calculators)\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/convert.py\u001b[0m in \u001b[0;36mconvert_sklearn\u001b[0;34m(model, name, initial_types, doc_string, target_opset, custom_conversion_functions, custom_shape_calculators, custom_parsers, options, intermediate, white_op, black_op, final_types, dtype, naming, verbose)\u001b[0m\n\u001b[1;32m    184\u001b[0m     onnx_model = convert_topology(\n\u001b[1;32m    185\u001b[0m         \u001b[0mtopology\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_opset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         remove_identity=not intermediate, verbose=verbose)\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[convert_sklearn] end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_topology\u001b[0;34m(topology, model_name, doc_string, target_opset, channel_first_inputs, options, remove_identity, verbose)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[0;31m# Traverse the graph from roots to leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;31m# This loop could eventually be parallelized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1421\u001b[0;31m     \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_operators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1422\u001b[0m     \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_topological_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mconvert_operators\u001b[0;34m(self, container, verbose)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_shape_calculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m                     \u001b[0;31m# If an operator contains a sequence of operators,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_topology.py\u001b[0m in \u001b[0;36mcall_converter\u001b[0;34m(self, operator, container, verbose)\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_fed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             \"\".join(str(i.is_fed) for i in operator.outputs))\n\u001b[0;32m-> 1062\u001b[0;31m         \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscopes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1063\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[Conv] end - %r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/common/_registration.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_operator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_allowed_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/stacking.py\u001b[0m in \u001b[0;36mconvert_sklearn_stacking_classifier\u001b[0;34m(scope, operator, container)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     merged_proba_tensor = _transform(\n\u001b[0;32m--> 122\u001b[0;31m         scope, operator, container, stacking_op)\n\u001b[0m\u001b[1;32m    123\u001b[0m     merge_proba = scope.declare_local_variable(\n\u001b[1;32m    124\u001b[0m             'merged_stacked_proba', operator.inputs[0].type.__class__())\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/stacking.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(scope, operator, container, model)\u001b[0m\n\u001b[1;32m     63\u001b[0m         _fetch_scores(scope, container, est, operator.inputs[0],\n\u001b[1;32m     64\u001b[0m                       raw_scores=meth == 'decision_function')\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'drop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     ]\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/stacking.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m                       raw_scores=meth == 'decision_function')\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack_method_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mest\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'drop'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m     ]\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/skl2onnx/operator_converters/stacking.py\u001b[0m in \u001b[0;36m_fetch_scores\u001b[0;34m(scope, container, model, inputs, raw_scores, is_regressor)\u001b[0m\n\u001b[1;32m     16\u001b[0m def _fetch_scores(scope, container, model, inputs, raw_scores=False,\n\u001b[1;32m     17\u001b[0m                   is_regressor=False):\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mop_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn_operator_name_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mthis_operator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeclare_local_operator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'raw_scores'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: <class 'catboost.core.CatBoostClassifier'>"
          ]
        }
      ]
    }
  ]
}